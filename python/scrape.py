
import requests
import shutil
from bs4 import BeautifulSoup
from datetime import datetime

def crawl(url):
    req = requests.get(url)

    if(req.status_code != 200):
        return

    soup = BeautifulSoup(req.text, 'html.parser')

    date_str = soup.find(class_="comic-date").get_text().strip()
    date_object = datetime.strptime(date_str, '%B %d, %Y')
    date_fmt = date_object.strftime('%Y-%m-%d')
    print date_fmt

    img_url = soup.find(class_='entry-content').find('img').get('src')
    r = requests.get(img_url, stream=True)
    if r.status_code == 200:
        with open("data/%s.gif" % date_fmt, 'wb') as f:
            r.raw.decode_content = True
            shutil.copyfileobj(r.raw, f)

    previous = soup.find(id="previouscomic").find('a').get('href')

    crawl(previous)


crawl('http://intelligentlifecomics.com/comics/october-20-2016/')
